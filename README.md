TM-LSTM
This repository contains the official PyTorch implementation of the paper â€‹â€‹"Research on the enhancement method of offshore vessel characteristics based on Transplanting Memory LSTM"â€‹â€‹.

We propose a novel â€‹â€‹Tâ€‹â€‹ransplanting â€‹â€‹Mâ€‹â€‹emory â€‹â€‹Lâ€‹â€‹ong â€‹â€‹Sâ€‹â€‹hort-â€‹â€‹Tâ€‹â€‹erm â€‹â€‹Mâ€‹â€‹emory (TM-LSTM) network for enhancing underwater acoustic signals in complex shallow-sea environments. The model effectively addresses challenges such as environmental noise interference and time-frequency feature ambiguity by capturing long-term dependencies and physical attenuation patterns.

Key Features / Innovationsï¼š

â€‹â€‹ðŸ§  Transplanting Memory Mechanism:â€‹â€‹ Introduces a cross-layer memory transfer mechanism to capture physical attenuation patterns in time-varying channels, enhancing the extraction of low-frequency energy concentration features.
â€‹â€‹ðŸŽ­ Encoder-Separator-Decoder Topology:â€‹â€‹ Employs a multi-scale feature decoupling architecture. A convolutional encoder extracts nonlinear features, a memory-augmented separator performs contextual aggregation for domain-invariant features, and a transposed decoder reconstructs high-fidelity signals.
â€‹â€‹ðŸŒŠ Region-Specific Optimization:â€‹â€‹ The model is specifically optimized and validated using a custom dataset from the â€‹â€‹Yellow Seaâ€‹â€‹, demonstrating strong generalization across different vessel types. It is also evaluated on public datasets (VesselsEar/DeepVessel).
â€‹â€‹ðŸ“ˆ Superior Performance:â€‹â€‹ Achieves significant improvements in Signal-to-Noise Ratio (SNR) and Scale-Invariant Signal-to-Distortion Ratio (SI-SDR) on two distinct denoising tasks.

Model Architectureï¼š
The TM-LSTM framework segments input acoustic signals and processes them through Segmented LSTM (Seg-LSTM) units for local feature modeling. A centralized Memory LSTM (Mem-LSTM) module aggregates long-term contextual information from all segments, minimizing redundancy and enhancing feature retention.

â€‹â€‹Encoder:â€‹â€‹ Projects the input signal into a sparse feature space using 1D convolutional layers.
â€‹â€‹Separator:â€‹â€‹ The core TM-LSTM module. It decouples features by leveraging shared hidden and cell states across Seg-LSTM and Mem-LSTM units.
â€‹â€‹Decoder:â€‹â€‹ Reconstructs the denoised signal via transposed convolutional operations and the overlap-add method.


ðŸš€ Quick Start

1.Prepare the data:â€‹â€‹Organize your audio data according to the structure in config. You can use the provided scripts in scripts format the Yellow Sea dataset or your own data.

2.Train the model:â€‹â€‹ Run the training script. Configuration can be modified in config.

3.â€‹â€‹Use your data:Use the pre-trained model (or your trained model) to enhance an audio file

